{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==0.18.rc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS07RNn-r8oh",
        "outputId": "92efe078-0c2d-40dd-a63f-cd7e31c737e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==0.18.rc2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for scikit-learn==0.18.rc2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JzUPztwqFYSJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1By3oyHnjHL",
        "outputId": "26fc2739-a7b3-4df6-d743-108cfc70c3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fe4add78dc44>:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "# mlp.rcParams['font.family'] = 'serif'\n",
        "%matplotlib inline\n",
        "\n",
        "from pandas import datetime\n",
        "import math, time\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "cGq0BegpExVo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "n48w4hH4HBgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU not available, CPU used\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH4I7ADXE0RY",
        "outputId": "4e68dcec-d060-4142-9aff-b443db738d70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Va9eK53mFhqa",
        "outputId": "e51de0d4-b111-4c7c-be3b-ee17b6f724a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4dc9e05e-6729-4b0c-876c-29114295479c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4dc9e05e-6729-4b0c-876c-29114295479c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMDB Dataset.csv to IMDB Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYmeNDvjIpEz",
        "outputId": "7dc37a4f-2bfa-4450-99d4-ab07862878c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "_vXHHel3Iuus"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp IMDB Dataset.csv ~/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiCBxfriIur3",
        "outputId": "3405abb4-fad8-448e-f165-f6e3bddcf7fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'IMDB': No such file or directory\n",
            "cp: cannot stat 'Dataset.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_csv = '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDBDataset.csv'"
      ],
      "metadata": {
        "id": "o8vtrFmUHTiF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'IMDB Dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vRXTsMXuHSB2",
        "outputId": "6ef8e949-2bf1-4c34-c51e-25bc1d3b411a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150ca6a3-0dee-4b4b-9584-34b044545763\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150ca6a3-0dee-4b4b-9584-34b044545763')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-150ca6a3-0dee-4b4b-9584-34b044545763 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-150ca6a3-0dee-4b4b-9584-34b044545763');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data to train and test data"
      ],
      "metadata": {
        "id": "l8-5ndKmJmhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66unkh8eKfSi",
        "outputId": "32569eb7-cd9a-4106-ef31-6de8584b1095"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       object\n",
              "sentiment    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = df['review'].values, df['sentiment'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)\n",
        "print(f'shape of train data is {x_train.shape}')\n",
        "print(f'shape of test data is {x_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYbwOQg7Jade",
        "outputId": "acc98106-3dd0-4005-e84d-36bbfdd6ae78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (37500,)\n",
            "shape of test data is (12500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysing sentiment"
      ],
      "metadata": {
        "id": "K5CoF9QdKKis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=np.array(['negative', 'positive']), y = dd.values)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qV7beKoxKHMD",
        "outputId": "f45b8f3f-02e7-489b-b42a-d7c531655977"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "XrEu3ZiGK8f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals.blocks import final\n",
        "def preprocess_string(s):\n",
        "  s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "  s = re.sub(r\"\\s+\", '', s)\n",
        "  s = re.sub(r\"\\d\", '', s)\n",
        "  return s\n",
        "\n",
        "def tockenize(x_train, y_train, x_val, y_val):\n",
        "  word_list = []\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  for sent in x_train:\n",
        "    for word in sent.lower().split():\n",
        "      word = preprocess_string(word)\n",
        "      if word not in stop_words and word != '':\n",
        "        word_list.append(word)\n",
        "  \n",
        "  corpus = Counter(word_list)\n",
        "  corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:1000]\n",
        "  onehot_dict = {w:i+1 for i, w in enumerate(corpus_)}\n",
        "  \n",
        "\n",
        "  final_list_train,final_list_test = [],[]\n",
        "  for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "  for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "  encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
        "  encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
        "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "pzDDBMOCKafK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk.download()\n",
        "\n",
        "from nltk.corpus import brown"
      ],
      "metadata": {
        "id": "c4HuSlHQOaXZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr2gnhBNPtta",
        "outputId": "988dc6ab-28b4-4330-8f36-e8377dc657f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2W-4CbFM-7J",
        "outputId": "f241bf60-e86f-4378-bf5c-20a2af3b0fd4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-27940a7e7272>:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx52UTK8Njj7",
        "outputId": "0c0868e1-b51d-4c23-c82f-984e76b22856"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysing review length"
      ],
      "metadata": {
        "id": "if9_EBPaStA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "GcVlGOKiSrXq",
        "outputId": "6ca10c57-750d-47a3-a4b2-31613521cd0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    37500.000000\n",
              "mean        69.190240\n",
              "std         48.178478\n",
              "min          0.000000\n",
              "25%         39.000000\n",
              "50%         54.000000\n",
              "75%         84.000000\n",
              "max        653.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ],
      "metadata": {
        "id": "XYB3HEM3TnUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "  features = np.zeros((len(sentences), seq_len), dtype=int)\n",
        "  for ii, review in enumerate(sentences):\n",
        "    if len(review) != 0:\n",
        "      features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "hib9E7ELS8TO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We have very less number of reviews with length > 500\n",
        "# So we will consider only below it.\n",
        "x_train_pad = padding_(x_train, 500)\n",
        "x_test_pad = padding_(x_test, 500)\n"
      ],
      "metadata": {
        "id": "17nQ9_Rs4Nxv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching and loading as tensor"
      ],
      "metadata": {
        "id": "184k-kZj6CGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "7iTx2NMS6Agq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size())\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample input: \\n', sample_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxuhZ6rs9-HK",
        "outputId": "02d05598-f951-45f9-ecc6-088f06417eb4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 500])\n",
            "Sample input: \n",
            " tensor([[  0,   0,   0,  ..., 445, 952, 446],\n",
            "        [  0,   0,   0,  ..., 984, 643, 145],\n",
            "        [  0,   0,   0,  ...,  32, 269, 330],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 154, 177,  24],\n",
            "        [  0,   0,   0,  ..., 208,   8, 676],\n",
            "        [  0,   0,   0,  ..., 967, 446, 150]])\n",
            "Sample input: \n",
            " tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
            "        0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "vTksIeXyHdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self, no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5):\n",
        "    super(SentimentRNN, self).__init__()\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.no_layers = no_layers\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim, num_layers=no_layers, batch_first=True)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    sig_out = sig_out[:, -1]\n",
        "\n",
        "    return sig_out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "\n",
        "    h0 = torch.zeros((self.no_layers, batch_size, self.hidden_dim)).to(device)\n",
        "    c0 = torch.zeros((self.no_layers, batch_size, self.hidden_dim)).to(device)\n",
        "    hidden = (h0, c0)\n",
        "    return hidden\n"
      ],
      "metadata": {
        "id": "S3jVraCKCJT8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
        "\n",
        "#moving to gpu\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hh4Gy_YMrcr",
        "outputId": "1c09bcd3-4b15-4cf8-e98b-ef7b37ad1cc4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "098jmTwxeEPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "def acc(pred, label):\n",
        "  pred = torch.round(pred.squeeze())\n",
        "  return torch.sum(pred == label.squeeze().item())\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "TaYgw0-vVz3c"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "# Train for some number of epochs\n",
        "epoch_tr_loss, epoch_vl_loss = [], []\n",
        "epoch_tr_acc, epoch_vl_acc = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_losses = []\n",
        "  train_acc = 0.0\n",
        "  model.train()\n",
        "  # initialize hidden state\n",
        "  h = model.init_hidden(batch_size)\n",
        "  for inputs, labels in train_loader:\n",
        "    \n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    #creating new variables for the hidden state else backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    model.zero_grad()\n",
        "    output, h = model(inputs, h)\n",
        "\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    train_losses.append(loss.item())\n",
        "    accuracy = acc(output, labels)\n",
        "    train_acc += accuracy\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "  val_h = model.init_hidden(batch_size)\n",
        "  val_losses = []\n",
        "  val_acc = 0.0\n",
        "  model.eval()\n",
        "  for inputs, labels in valid_loader:\n",
        "    val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    output, val_h = model(inputs, val_h)\n",
        "    val_loss = criterion(output.squeeze(), labels.float())\n",
        "    val_losses.append(val_loss.item())\n",
        "    accuracy = acc(output, labels)\n",
        "    val_acc += accuracy\n",
        "\n",
        "  epoch_train_loss = np.mean(train_losses)\n",
        "  epoch_val_loss = np.mean(val_losses)\n",
        "  epoch_train_acc = val_acc/len(valid_loader.dataset)\n",
        "  epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "  epoch_tr_loss.append(epoch_val_loss)\n",
        "  epoch_vl_loss.append(epoch_val_loss)\n",
        "  epoch_tr_loss.append(epoch_train_acc)\n",
        "  epoch_vl_loss.append(epoch_val_acc)\n",
        "  print(f'Epoch {epoch+1}')\n",
        "  print(f'train_loss: {epoch_train_loss} val_loss: {epoch_val_loss}')\n",
        "  print(f'train_accuracy: {epoch_train_acc*100} val_accuracy: {epoch_val_acc * 100}')\n",
        "  if epoch_val_loss <= valid_loss_min:\n",
        "    torch.save(model.state_dict(), '../working/state_dict.pt')\n",
        "\n",
        "    print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(valid_loss_min, epoch_val_loss))\n",
        "  print(25*'==')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "RcWR_eJaeyia",
        "outputId": "f4d6a061-64d1-41c0-e914-f399054f8937"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-69950cd114e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([25000])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 5 \n",
        "valid_loss_min = np.Inf\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state \n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device)   \n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        " \n",
        "    \n",
        "        \n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "            \n",
        "            accuracy = acc(output,labels)\n",
        "            val_acc += accuracy\n",
        "            \n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}') \n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "RRa2kHDNgNvH",
        "outputId": "ddc836c1-fdc6-4d1b-ba56-4531ef21ef43"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-088e340377eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([25000])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch_tr_acc, label='Train Acc')\n",
        "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch_tr_loss, label='Train loss')\n",
        "plt.plot(epoch_vl_loss, label='Validation loss')\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "eqP0QFBBXPEw",
        "outputId": "7a6f63b2-2332-4f07-c453-ffa01095408e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferance"
      ],
      "metadata": {
        "id": "eDG8bazHYAr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "  word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() if preprocess_string(word) in vocab.keys()])\n",
        "  word_seq = np.expand_dims(word_seq, axis=0)\n",
        "  pad = torch.from_numpy(padding_(word_seq, 500))\n",
        "  inputs = pad.to(device)\n",
        "  batch_size = 1\n",
        "  h = model.init_hidden(batch_size)\n",
        "  h = tuple([each.data for each in h])\n",
        "  output, h = model(inputs, h)\n",
        "  return(output.item())\n",
        "  \n",
        "                  "
      ],
      "metadata": {
        "id": "Kmkyv5YgX6qq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 30\n",
        "print(df['review'][index])\n",
        "print('='*70)\n",
        "print(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\n",
        "print('='*70)\n",
        "pro = predict_text(df['review'][index])\n",
        "status = \"positive\" if pro > 0.5 else \"negative\"\n",
        "pro = (1 - pro) if status == \"negative\" else pro\n",
        "print(f'Predicted sentiment is {status} with a probability of {pro}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "1N0DFMFYZE5X",
        "outputId": "045f9d4b-a7f2-4664-a231-a8565270505b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taut and organically gripping, Edward Dmytryk's Crossfire is a distinctive suspense thriller, an unlikely \"message\" movie using the look and devices of the noir cycle.<br /><br />Bivouacked in Washington, DC, a company of soldiers cope with their restlessness by hanging out in bars. Three of them end up at a stranger's apartment where Robert Ryan, drunk and belligerent, beats their host (Sam Levene) to death because he happens to be Jewish. Police detective Robert Young investigates with the help of Robert Mitchum, who's assigned to Ryan's outfit. Suspicion falls on the second of the three (George Cooper), who has vanished. Ryan slays the third buddy (Steve Brodie) to insure his silence before Young closes in.<br /><br />Abetted by a superior script by John Paxton, Dmytryk draws precise performances from his three starring Bobs. Ryan, naturally, does his prototypical Angry White Male (and to the hilt), while Mitchum underplays with his characteristic alert nonchalance (his role, however, is not central); Young may never have been better. Gloria Grahame gives her first fully-fledged rendition of the smart-mouthed, vulnerable tramp, and, as a sad sack who's leeched into her life, Paul Kelly haunts us in a small, peripheral role that he makes memorable.<br /><br />The politically engaged Dmytryk perhaps inevitably succumbs to sermonizing, but it's pretty much confined to Young's reminiscence of how his Irish grandfather died at the hands of bigots a century earlier (thus, incidentally, stretching chronology to the limit). At least there's no attempt to render an explanation, however glib, of why Ryan hates Jews (and hillbillies and...).<br /><br />Curiously, Crossfire survives even the major change wrought upon it -- the novel it's based on (Richard Brooks' The Brick Foxhole) dealt with a gay-bashing murder. But homosexuality in 1947 was still Beyond The Pale. News of the Holocaust had, however, begun to emerge from the ashes of Europe, so Hollywood felt emboldened to register its protest against anti-Semitism (the studios always quaked at the prospect of offending any potential ticket buyer).<br /><br />But while the change from homophobia to anti-Semitism works in general, the specifics don't fit so smoothly. The victim's chatting up a lonesome, drunk young soldier then inviting him back home looks odd, even though (or especially since) there's a girlfriend in tow. It raises the question whether this scenario was retained inadvertently or left in as a discreet tip-off to the original engine generating Ryan's murderous rage.\n",
            "======================================================================\n",
            "Actual sentiment is  : positive\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c827a309fce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Actual sentiment is  : {df[\"sentiment\"][index]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"positive\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpro\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpro\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"negative\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-43d77f0e130b>\u001b[0m in \u001b[0;36mpredict_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 32\n",
        "print(df['review'][index])\n",
        "print('='*70)\n",
        "print(f'Actual sentiment is: {df[\"sentiment\"][index]}')\n",
        "print('='*70)\n",
        "pro = predict_text(df['review'][index])\n",
        "status = \"positive\" if pro > 0.5 else \"negative\"\n",
        "pro = (1-pro) if status == \"negative\" else pro\n",
        "print(f'predicted sentiment is {status} with a probability of {pro}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "mlysyFi6Zwmh",
        "outputId": "d4a83ccb-5f4a-40a9-c4af-628cedbbe713"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My first exposure to the Templarios & not a good one. I was excited to find this title among the offerings from Anchor Bay Video, which has brought us other cult classics such as \"Spider Baby\". The print quality is excellent, but this alone can't hide the fact that the film is deadly dull. There's a thrilling opening sequence in which the villagers exact a terrible revenge on the Templars (& set the whole thing in motion), but everything else in the movie is slow, ponderous &, ultimately, unfulfilling. Adding insult to injury: the movie was dubbed, not subtitled, as promised on the video jacket.\n",
            "======================================================================\n",
            "Actual sentiment is: negative\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-ef516ba5238e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Actual sentiment is: {df[\"sentiment\"][index]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"positive\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpro\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpro\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"negative\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-43d77f0e130b>\u001b[0m in \u001b[0;36mpredict_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqxeaPnCaZIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}